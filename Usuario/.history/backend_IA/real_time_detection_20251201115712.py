"""
Script mejorado para reconocimiento de lenguaje de se√±as en tiempo real
"""
import cv2
import numpy as np
import mediapipe as mp
from tensorflow.keras.models import load_model
from config import *
import os
from collections import Counter

# Inicializar MediaPipe
mp_holistic = mp.solutions.holistic
mp_drawing = mp.solutions.drawing_utils

def mediapipe_detection(image, model):
    """Detectar puntos clave usando MediaPipe"""
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image.flags.writeable = False
    results = model.process(image)
    image.flags.writeable = True
    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
    return image, results

def draw_styled_landmarks(image, results):
    """Dibujar los puntos detectados con estilo"""
    # Mano derecha
    mp_drawing.draw_landmarks(
        image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,
        mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),
        mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)
    )
    # Mano izquierda
    mp_drawing.draw_landmarks(
        image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,
        mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),
        mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)
    )
    # Pose
    mp_drawing.draw_landmarks(
        image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,
        mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),
        mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)
    )

def extract_keypoints(results):
    """Extraer coordenadas de los puntos clave"""
    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)
    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)
    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)
    return np.concatenate([pose, lh, rh])

def prob_viz(res, actions, input_frame, colors, max_prob_idx):
    """Visualizar probabilidades de cada se√±a con mejora visual"""
    output_frame = input_frame.copy()
    for num, prob in enumerate(res):
        # Resaltar la predicci√≥n m√°s probable
        if num == max_prob_idx:
            color = (0, 255, 0)  # Verde para la m√°s probable
            thickness = 3
        else:
            color = colors[num]
            thickness = 2
        
        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), color, -1)
        cv2.putText(output_frame, f'{actions[num]}: {prob*100:.1f}%', (105, 85+num*40), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), thickness, cv2.LINE_AA)
    return output_frame

def run_detection():
    """Funci√≥n principal de detecci√≥n en tiempo real mejorada"""
    # Cargar modelo
    model_path = os.path.join(MODELS_DIR, 'best_model.keras')
    
    if not os.path.exists(model_path):
        print("‚ùå Error: No se encontr√≥ el modelo entrenado.")
        print("   Ejecuta train_model.py primero.")
        return
    
    print("üìÇ Cargando modelo...")
    model = load_model(model_path)
    print("‚úì Modelo cargado exitosamente\n")
    
    # Colores para cada se√±a
    colors = [(245,117,16), (117,245,16), (16,117,245), (245,16,117), (16,245,117), (117,16,245)]
    
    # Variables para la detecci√≥n
    sequence = []
    sentence = []
    predictions = []
    last_predictions = []  # Para suavizado
    threshold = 0.5  # Umbral REDUCIDO de 0.7 a 0.5
    smoothing_window = 15  # Ventana para suavizado
    
    # Abrir c√°mara
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    
    print("=" * 60)
    print("üé• RECONOCIMIENTO EN TIEMPO REAL - VERSI√ìN MEJORADA")
    print("=" * 60)
    print("\n‚ú® Mejoras aplicadas:")
    print("   - Umbral de confianza reducido a 50%")
    print("   - Sistema de suavizado de predicciones")
    print("   - Visualizaci√≥n mejorada de probabilidades")
    print("\nInstrucciones:")
    print("   - Haz las se√±as frente a la c√°mara")
    print("   - Mant√©n la se√±a 1-2 segundos para mejor detecci√≥n")
    print("   - La barra VERDE indica la predicci√≥n actual")
    print("   - Presiona 'q' para salir")
    print("   - Presiona 'c' para limpiar el historial")
    print("-" * 60 + "\n")
    
    with mp_holistic.Holistic(
        min_detection_confidence=0.5,  # Reducido de 0.5
        min_tracking_confidence=0.5
    ) as holistic:
        
        while cap.isOpened():
            ret, frame = cap.read()
            
            if not ret:
                break
            
            # Voltear horizontalmente para efecto espejo
            frame = cv2.flip(frame, 1)
            
            # Hacer detecci√≥n
            image, results = mediapipe_detection(frame, holistic)
            
            # Dibujar landmarks
            draw_styled_landmarks(image, results)
            
            # Extraer keypoints
            keypoints = extract_keypoints(results)
            sequence.append(keypoints)
            sequence = sequence[-30:]  # Mantener solo los √∫ltimos 30 frames
            
            # Hacer predicci√≥n si tenemos suficientes frames
            if len(sequence) == 30:
                res = model.predict(np.expand_dims(sequence, axis=0), verbose=0)[0]
                max_prob_idx = np.argmax(res)
                max_prob = res[max_prob_idx]
                
                # Agregar a historial de predicciones
                last_predictions.append(max_prob_idx)
                last_predictions = last_predictions[-smoothing_window:]
                
                # Predicci√≥n suavizada (moda de las √∫ltimas predicciones)
                if len(last_predictions) >= 5:
                    most_common = Counter(last_predictions).most_common(1)[0]
                    smoothed_pred = most_common[0]
                    smoothed_count = most_common[1]
                    
                    # Solo agregar si hay consistencia y supera el umbral
                    if smoothed_count >= 8 and res[smoothed_pred] > threshold:
                        if len(sentence) > 0:
                            if SIGNS[smoothed_pred] != sentence[-1]:
                                sentence.append(SIGNS[smoothed_pred])
                                last_predictions = []  # Reset despu√©s de detecci√≥n
                        else:
                            sentence.append(SIGNS[smoothed_pred])
                            last_predictions = []
                
                # Visualizaci√≥n de probabilidades
                image = prob_viz(res, SIGNS, image, colors, max_prob_idx)
                
                # Indicador de confianza
                confidence_color = (0, 255, 0) if max_prob > threshold else (0, 165, 255)
                cv2.putText(image, f'Confianza: {max_prob*100:.1f}%', (400, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, confidence_color, 2, cv2.LINE_AA)
                
                # Mantener √∫ltimas 5 predicciones
                if len(sentence) > 5:
                    sentence = sentence[-5:]
                
                # Mostrar texto de predicci√≥n
                cv2.rectangle(image, (0,0), (640, 50), (245, 117, 16), -1)
                display_text = ' ‚Üí '.join(sentence) if sentence else 'Esperando se√±as...'
                cv2.putText(image, display_text, (10,35), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2, cv2.LINE_AA)
            else:
                # Mostrar mensaje de espera
                cv2.rectangle(image, (0,0), (640, 50), (100, 100, 100), -1)
                cv2.putText(image, 'Inicializando...', (10,35), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2, cv2.LINE_AA)
            
            # Mostrar frame
            cv2.imshow('Reconocimiento de Lenguaje de Se√±as', image)
            
            # Controles de teclado
            key = cv2.waitKey(10) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('c'):
                sentence = []
                last_predictions = []
                print("üîÑ Historial limpiado")
        
        cap.release()
        cv2.destroyAllWindows()
        print("\n‚úÖ Sesi√≥n finalizada")
        if sentence:
            print(f"üìù Se√±as detectadas: {' ‚Üí '.join(sentence)}")

if __name__ == "__main__":
    try:
        run_detection()
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()